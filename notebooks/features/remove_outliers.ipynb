{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_pickle(\"../../data/interim/01_data_processed.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "outlierColumns = list(df.columns[:6])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def plot_binary_outliers(dataset, col, outlier_col, reset_index):\n",
    "    \"\"\" Plot outliers in case of a binary outlier score. Here, the col specifies the real data\n",
    "    column and outlier_col the columns with a binary value (outlier or not).\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset\n",
    "        col (string): Column that you want to plot\n",
    "        outlier_col (string): Outlier column marked with true/false\n",
    "        reset_index (bool): whether to reset the index for plotting\n",
    "    \"\"\"\n",
    "\n",
    "    # Taken from: https://github.com/mhoogen/ML4QS/blob/master/Python3Code/util/VisualizeDataset.py\n",
    "\n",
    "    dataset = dataset.dropna(axis=0, subset=[col, outlier_col])\n",
    "    dataset[outlier_col] = dataset[outlier_col].astype(\"bool\")\n",
    "\n",
    "    if reset_index:\n",
    "        dataset = dataset.reset_index()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.xlabel(\"samples\")\n",
    "    plt.ylabel(\"value\")\n",
    "\n",
    "    # Plot non outliers in default color\n",
    "    ax.plot(\n",
    "        dataset.index[~dataset[outlier_col]],\n",
    "        dataset[col][~dataset[outlier_col]],\n",
    "        \"+\",\n",
    "    )\n",
    "    # Plot data points that are outliers in red\n",
    "    ax.plot(\n",
    "        dataset.index[dataset[outlier_col]],\n",
    "        dataset[col][dataset[outlier_col]],\n",
    "        \"r+\",\n",
    "    )\n",
    "\n",
    "    plt.legend(\n",
    "        [\"outlier \" + col, \"no outlier \" + col],\n",
    "        loc=\"upper center\",\n",
    "        ncol=2,\n",
    "        fancybox=True,\n",
    "        shadow=True,\n",
    "    )\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def mark_outliers_chauvenet(dataset, col, C=2):\n",
    "    \"\"\"Finds outliers in the specified column of datatable and adds a binary column with\n",
    "    the same name extended with '_outlier' that expresses the result per data point.\n",
    "    \n",
    "    Taken from: https://github.com/mhoogen/ML4QS/blob/master/Python3Code/Chapter3/OutlierDetection.py\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset\n",
    "        col (string): The column you want apply outlier detection to\n",
    "        C (int, optional): Degree of certainty for the identification of outliers given the assumption \n",
    "                           of a normal distribution, typicaly between 1 - 10. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original dataframe with an extra boolean column \n",
    "        indicating whether the value is an outlier or not.\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = dataset.copy()\n",
    "    # Compute the mean and standard deviation.\n",
    "    mean = dataset[col].mean()\n",
    "    std = dataset[col].std()\n",
    "    N = len(dataset.index)\n",
    "    criterion = 1.0 / (C * N)\n",
    "\n",
    "    # Consider the deviation for the data points.\n",
    "    deviation = abs(dataset[col] - mean) / std\n",
    "\n",
    "    # Express the upper and lower bounds.\n",
    "    low = -deviation / math.sqrt(C)\n",
    "    high = deviation / math.sqrt(C)\n",
    "    prob = []\n",
    "    mask = []\n",
    "\n",
    "    # Pass all rows in the dataset.\n",
    "    for i in range(0, len(dataset.index)):\n",
    "        # Determine the probability of observing the point\n",
    "        prob.append(\n",
    "            1.0 - 0.5 * (scipy.special.erf(high[i]) - scipy.special.erf(low[i]))\n",
    "        )\n",
    "        # And mark as an outlier when the probability is below our criterion.\n",
    "        mask.append(prob[i] < criterion)\n",
    "    dataset[col + \"_outlier\"] = mask\n",
    "    return dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "outlierRemovedDF = df.copy() # copies the original DF."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "for perCol in outlierColumns:\n",
    "    for perLabel in df[\"label\"].unique():\n",
    "        dataset = mark_outliers_chauvenet(\n",
    "            df[df[\"label\"] == perLabel], perCol\n",
    "            )\n",
    "        \n",
    "        # This will dynamically replace outlier values to \n",
    "        # NaN to each column.\n",
    "        dataset.loc[dataset[perCol + \"_outlier\"], perCol] = np.nan\n",
    "        \n",
    "        # Update the column in the original dataframe.\n",
    "        # Very advance technique, I need to understand this.\n",
    "        outlierRemovedDF.loc[(outlierRemovedDF[\"label\"] == perLabel), perCol] = dataset[perCol]\n",
    "        \n",
    "        nOutliers = len(dataset) - len(dataset[perCol].dropna())\n",
    "        print(f\"Remove {nOutliers} from {perCol} for {perLabel}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Remove 0 from acce_x for bench\n",
      "Remove 2 from acce_x for ohp\n",
      "Remove 0 from acce_x for squat\n",
      "Remove 2 from acce_x for dead\n",
      "Remove 0 from acce_x for row\n",
      "Remove 0 from acce_x for rest\n",
      "Remove 5 from acce_y for bench\n",
      "Remove 6 from acce_y for ohp\n",
      "Remove 0 from acce_y for squat\n",
      "Remove 0 from acce_y for dead\n",
      "Remove 0 from acce_y for row\n",
      "Remove 0 from acce_y for rest\n",
      "Remove 3 from acce_z for bench\n",
      "Remove 6 from acce_z for ohp\n",
      "Remove 0 from acce_z for squat\n",
      "Remove 1 from acce_z for dead\n",
      "Remove 0 from acce_z for row\n",
      "Remove 0 from acce_z for rest\n",
      "Remove 2 from gyro_x for bench\n",
      "Remove 4 from gyro_x for ohp\n",
      "Remove 1 from gyro_x for squat\n",
      "Remove 6 from gyro_x for dead\n",
      "Remove 0 from gyro_x for row\n",
      "Remove 12 from gyro_x for rest\n",
      "Remove 14 from gyro_y for bench\n",
      "Remove 15 from gyro_y for ohp\n",
      "Remove 9 from gyro_y for squat\n",
      "Remove 14 from gyro_y for dead\n",
      "Remove 10 from gyro_y for row\n",
      "Remove 9 from gyro_y for rest\n",
      "Remove 13 from gyro_z for bench\n",
      "Remove 1 from gyro_z for ohp\n",
      "Remove 12 from gyro_z for squat\n",
      "Remove 14 from gyro_z for dead\n",
      "Remove 0 from gyro_z for row\n",
      "Remove 24 from gyro_z for rest\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "outlierRemovedDF.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9009 entries, 2019-01-11 15:08:05.200000 to 2019-01-20 17:33:27.800000\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   acce_x       9005 non-null   float64\n",
      " 1   acce_y       8998 non-null   float64\n",
      " 2   acce_z       8999 non-null   float64\n",
      " 3   gyro_x       8984 non-null   float64\n",
      " 4   gyro_y       8938 non-null   float64\n",
      " 5   gyro_z       8945 non-null   float64\n",
      " 6   participant  9009 non-null   object \n",
      " 7   label        9009 non-null   object \n",
      " 8   category     9009 non-null   object \n",
      " 9   set          9009 non-null   int32  \n",
      "dtypes: float64(6), int32(1), object(3)\n",
      "memory usage: 739.0+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# This shows that the code that I retained is correct since it has the same numbe of data from the OLD python files which has all the code becuase of the individual task."
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}